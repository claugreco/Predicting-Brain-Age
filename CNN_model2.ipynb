{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Model. \n",
    "#No Data Augmentation\n",
    "#Hyperparameters tunning with Hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.utils import np_utils\n",
    "import h5py\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    nb_classes = 1\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    y= df['label']\n",
    "    X= df.drop('label', axis=1)\n",
    "\n",
    "    # Train/Test Split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=142)\n",
    "    \n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], 256, 150, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 256, 150, 1)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    nb_epoch = 15\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 256, 150\n",
    "    img_channels = 1\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D({{choice([90, 180])}}, (5,5), padding='same',\n",
    "                            input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (4,4), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([1024, 2048])}}))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    adam = Adam()\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=adam, \n",
    "                  metrics=['mean_squared_error'])\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    model.fit(X_train, Y_train,\n",
    "            batch_size=128,\n",
    "            epochs=nb_epoch,\n",
    "            validation_data=(X_test, Y_test))\n",
    "\n",
    "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (345, 38400)\n",
      "345 train samples\n",
      "148 test samples\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error, r2_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_absolute_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import gc\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: nb_classes = 1\n",
      "  3: \n",
      "  4: df = pd.read_csv('data.csv')\n",
      "  5: df = df.drop('Unnamed: 0', axis=1)\n",
      "  6: y= df['label']\n",
      "  7: X= df.drop('label', axis=1)\n",
      "  8: \n",
      "  9: # Train/Test Split\n",
      " 10: X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=142)\n",
      " 11: \n",
      " 12: print('X_train shape:', X_train.shape)\n",
      " 13: print(X_train.shape[0], 'train samples')\n",
      " 14: print(X_test.shape[0], 'test samples')\n",
      " 15: \n",
      " 16: scaler = MinMaxScaler(feature_range = (0,1))\n",
      " 17: X_train = scaler.fit_transform(X_train)\n",
      " 18: X_test = scaler.fit_transform(X_test)\n",
      " 19: \n",
      " 20: X_train = X_train.reshape(X_train.shape[0], 256, 150, 1)\n",
      " 21: X_test = X_test.reshape(X_test.shape[0], 256, 150, 1)\n",
      " 22: \n",
      " 23: \n",
      " 24: \n",
      " 25: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     nb_epoch = 15\n",
      "   5: \n",
      "   6:     # input image dimensions\n",
      "   7:     img_rows, img_cols = 256, 150\n",
      "   8:     img_channels = 1\n",
      "   9: \n",
      "  10:     model = Sequential()\n",
      "  11: \n",
      "  12:     model.add(Conv2D(90, (5,5), padding='same',\n",
      "  13:                             input_shape=X_train.shape[1:]))\n",
      "  14:     model.add(Activation('relu'))\n",
      "  15:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  16: \n",
      "  17:     model.add(Conv2D(180, (4,4), padding='same'))\n",
      "  18:     model.add(Activation('relu'))\n",
      "  19:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  20:     model.add(Dropout(space['Dropout']))\n",
      "  21: \n",
      "  22:     model.add(Flatten())\n",
      "  23:     model.add(Dense(1024))\n",
      "  24:     model.add(Activation('relu'))\n",
      "  25:     model.add(Dropout(0.5))\n",
      "  26:     \n",
      "  27:     model.add(Dense(nb_classes))\n",
      "  28:     model.add(Activation('relu'))\n",
      "  29: \n",
      "  30:     adam = Adam()\n",
      "  31:     model.compile(loss='mean_absolute_error',\n",
      "  32:                   optimizer=adam, \n",
      "  33:                   metrics=['mean_squared_error'])\n",
      "  34: \n",
      "  35:     # fit the model on the batches generated by datagen.flow()\n",
      "  36:     model.fit(X_train, Y_train,\n",
      "  37:             batch_size=128,\n",
      "  38:             epochs=nb_epoch,\n",
      "  39:             validation_data=(X_test, Y_test))\n",
      "  40: \n",
      "  41:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
      "  42: \n",
      "  43:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  44: \n",
      "X_train shape: (345, 38400)\n",
      "345 train samples\n",
      "148 test samples\n",
      "Train on 345 samples, validate on 148 samples\n",
      "Epoch 1/15\n",
      "345/345 [==============================] - 910s 3s/step - loss: 46.1790 - mean_squared_error: 3721.2503 - val_loss: 43.9760 - val_mean_squared_error: 2278.8726\n",
      "Epoch 2/15\n",
      "345/345 [==============================] - 1079s 3s/step - loss: 43.7612 - mean_squared_error: 2232.8248 - val_loss: 35.1084 - val_mean_squared_error: 1625.0159\n",
      "Epoch 3/15\n",
      "345/345 [==============================] - 1140s 3s/step - loss: 32.6997 - mean_squared_error: 1373.3931 - val_loss: 30.4235 - val_mean_squared_error: 1669.4127\n",
      "Epoch 4/15\n",
      "128/345 [==========>...................] - ETA: 9:57 - loss: 32.1356 - mean_squared_error: 1625.3008"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "best_run, best_model, space = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=2,\n",
    "                                          trials=Trials(),\n",
    "                                          eval_space=True,  \n",
    "                                          return_space=True,\n",
    "                                          notebook_name='CNN_model2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"best_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters of best run\", best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = best_model.predict(X_test)\n",
    "preds_train = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(preds, y_test, color='gray');\n",
    "plt.xlabel('CNN Predicted Age (years)')\n",
    "plt.plot([min(y_test),max(y_test)],[min(y_test),max(y_test)])\n",
    "plt.ylabel('Age (years)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(preds_train, y_train, color='gray');\n",
    "plt.xlabel('CNN Predicted Age (years)')\n",
    "plt.ylabel('Age (years)')\n",
    "plt.plot([min(y_train),max(y_train)],[min(y_train),max(y_train)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_score_test = r2_score(Y_test, preds_test)\n",
    "print (r_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_score_train = r2_score(Y_train, preds_train)\n",
    "print (r_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
